{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.ops.rnn_cell_impl' has no attribute '_Linear'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e930ce5091d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcrf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcudnn_rnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCudnnCompatibleGRUCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCudnnCompatibleLSTMCell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCudnnGRU\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn_rnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgen_cudnn_rnn_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlstm_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcommon_shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\rnn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[1;31m# pylint: disable=unused-import,wildcard-import,line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_rnn_cell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEmbeddingWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_rnn_cell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputProjectionWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore_rnn_cell\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOutputProjectionWrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\rnn\\python\\ops\\core_rnn_cell.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mRNNCell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_cell_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRNNCell\u001b[0m  \u001b[1;31m# pylint: disable=invalid-name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0m_Linear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_cell_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_Linear\u001b[0m  \u001b[1;31m# pylint: disable=invalid-name, protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0m_like_rnncell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnn_cell_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_like_rnncell\u001b[0m  \u001b[1;31m# pylint: disable=invalid-name, protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.ops.rnn_cell_impl' has no attribute '_Linear'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#Clear TF memory\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))\n",
    "\n",
    "mnist = input_data.read_data_sets('../Basic TF & things/mnist', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple RNN consists of\n",
    "## 1. One input layer which converts a 28 dimensional input to an 128 dimensional hidden layer\n",
    "## 2. One intermediate RNN (LSTM)\n",
    "## 3. One output layer which converts an 128 dimensional output of the LSTM to 10 dimensional output indicationg a class label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/rnn_input.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Params\n",
    "n_classes = mnist.train.labels.shape[1]\n",
    "learning_rate = 0.001\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "display_step = 2\n",
    "\n",
    "#Netword params\n",
    "dim_input = 28\n",
    "dim_hidden = 128\n",
    "dim_output = n_classes\n",
    "n_steps = 28\n",
    "\n",
    "#Weights & Biases\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal(shape=[dim_input, dim_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal(shape=[dim_hidden, dim_output]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal(shape=[dim_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal(shape=[dim_output]))\n",
    "}\n",
    "\n",
    "#Placeholders\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, n_steps, dim_input])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, dim_output])\n",
    "istate = tf.placeholder(dtype=tf.float32, shape=[None, 2*dim_hidden])         #state & cell => 2 * n_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, istate, weights, biases, nsteps, name):\n",
    "    # Permute input from [batch_size, nsteps, dim_input] -> [nsteps, batch_size, dim_input]\n",
    "    x = tf.transpose(a=x, perm=[1,0,2])\n",
    "    \n",
    "    # Reshape input to [nsteps * batch_size, dim_input]\n",
    "    x = tf.reshape(tensor=x, shape=[-1, dim_input])\n",
    "    \n",
    "    # Input layer -> Hidden layer\n",
    "    H = tf.matmul(x, weights['hidden']) + biases['hidden']\n",
    "    \n",
    "    # Split data to 'nsteps' chunks. An i-th chunk indicates i-th batch data\n",
    "#     H_split = tf.split(0, nsteps, H)\n",
    "    H_split = tf.split(value=H, num_or_size_splits=nsteps, axis=0)\n",
    "    \n",
    "    # Get LSTM's final output (LSTM_O) and state (LSTM_S)\n",
    "    #   Both LSTM_O & LSTM_S consist of batchsize elements\n",
    "    #   Only LSTM_O will be used to predict the output\n",
    "    \n",
    "    with tf.variable_scope(name):\n",
    "        lstm_cell = rnn.BasicLSTMCell(dim_hidden, forget_bias=1.0)\n",
    "        LSTM_O, LSTM_S = rnn.static_rnn(lstm_cell, H_split, dtype=tf.float32)\n",
    "        \n",
    "    # Output\n",
    "    O = tf.matmul(LSTM_O[-1], weights['out']) + biases['out']\n",
    "    \n",
    "    #Return\n",
    "    return {\n",
    "        'x': x,\n",
    "        'H': H,\n",
    "        'H_split': H_split,\n",
    "        'LSTM_O': LSTM_O,\n",
    "        'LSTM_S': LSTM_S,\n",
    "        'O': O\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](images/rnn_mnist_look.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-01575ca5a442>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_rnn = RNN(x, istate, weights, biases, n_steps, 'basic')\n",
    "y_pred = my_rnn['O']\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000/020,    Loss: 0.5199\n",
      "-->    Train Accuracy: 0.9921875\n",
      "-->    Test Accuracy: 0.9299\n",
      "Epoch 002/020,    Loss: 0.0883\n",
      "-->    Train Accuracy: 0.984375\n",
      "-->    Test Accuracy: 0.9734\n",
      "Epoch 004/020,    Loss: 0.0565\n",
      "-->    Train Accuracy: 1.0\n",
      "-->    Test Accuracy: 0.9796\n",
      "Epoch 006/020,    Loss: 0.0387\n",
      "-->    Train Accuracy: 1.0\n",
      "-->    Test Accuracy: 0.9772\n",
      "Epoch 008/020,    Loss: 0.0273\n",
      "-->    Train Accuracy: 0.984375\n",
      "-->    Test Accuracy: 0.9786\n",
      "Epoch 010/020,    Loss: 0.0225\n",
      "-->    Train Accuracy: 0.9921875\n",
      "-->    Test Accuracy: 0.978\n",
      "Epoch 012/020,    Loss: 0.0181\n",
      "-->    Train Accuracy: 0.9921875\n",
      "-->    Test Accuracy: 0.9794\n",
      "Epoch 014/020,    Loss: 0.0109\n",
      "-->    Train Accuracy: 1.0\n",
      "-->    Test Accuracy: 0.9826\n",
      "Epoch 016/020,    Loss: 0.0107\n",
      "-->    Train Accuracy: 1.0\n",
      "-->    Test Accuracy: 0.9805\n",
      "Epoch 018/020,    Loss: 0.0085\n",
      "-->    Train Accuracy: 1.0\n",
      "-->    Test Accuracy: 0.9829\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# summary_writer = tf.train.SummaryWriter('/tmp/tensorflow_logs', graph=sess.graph)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    avg_loss = 0\n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    #Loop over all batches\n",
    "    for i in range(total_batch):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        #Reshape the batch_x to use as input training RNN\n",
    "        batch_x = batch_x.reshape((batch_size, n_steps, dim_input))\n",
    "        \n",
    "        #Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, istate:np.zeros((batch_size, 2*dim_hidden))})\n",
    "        \n",
    "        #Compute avg_loss\n",
    "        avg_loss += sess.run(loss, feed_dict={x: batch_x, y: batch_y, istate: np.zeros((batch_size, 2*dim_hidden))}) / total_batch\n",
    "        \n",
    "    #Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        print('Epoch %03d/%03d,    Loss: %.4f' % (epoch, epochs, avg_loss))\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, istate: np.zeros((batch_size, 2*dim_hidden))})\n",
    "        test_images = mnist.test.images.reshape((mnist.test.images.shape[0], n_steps, dim_input))\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={x: test_images, y: mnist.test.labels, istate: np.zeros((mnist.test.images.shape[0], 2*dim_hidden))})\n",
    "        print('-->    Train Accuracy:', train_accuracy)\n",
    "        print('-->    Test Accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What will happen if we feed first 25 seq of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we use 25 seqs, Test accuracy becomes 0.859\n"
     ]
    }
   ],
   "source": [
    "n_steps2 = 25\n",
    "\n",
    "#Test with truncated inputs\n",
    "test_img = mnist.test.images.reshape((mnist.test.images.shape[0], n_steps, dim_input))\n",
    "test_img_truncated = np.zeros((test_img.shape))\n",
    "test_img_truncated[:, 28-n_steps2:] = test_img[:, :n_steps2, :]\n",
    "\n",
    "test_accuracy = sess.run(accuracy, feed_dict={x: test_img_truncated, y: mnist.test.labels, istate: np.zeros((mnist.test.images.shape[0], 2*dim_hidden))})\n",
    "print('If we use %d seqs, Test accuracy becomes %.3f' % (n_steps2, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## What is going on inside the RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input to the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test is  (5, 784)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "x_test, _ = mnist.test.next_batch(batch_size)\n",
    "print('Shape of x_test is ', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Reshaped inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_test1 is  (5, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#Reshape (this will go into the network)\n",
    "x_test1 = x_test.reshape((batch_size, n_steps, dim_input))\n",
    "print('Shape of x_test1 is ', x_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feeds: inputs and initial states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feeds = {x: x_test1, istate: np.zeros((batch_size, 2*dim_hidden))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each individual input the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of rnn_out_x is  (140, 28)\n"
     ]
    }
   ],
   "source": [
    "rnn_out_x = sess.run(my_rnn['x'], feed_dict=feeds)\n",
    "print('Shape of rnn_out_x is ', rnn_out_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each individual intermediate state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of rnn_out_H is  (140, 128)\n"
     ]
    }
   ],
   "source": [
    "rnn_out_H = sess.run(my_rnn['H'], feed_dict=feeds)\n",
    "print('Shape of rnn_out_H is ', rnn_out_H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual input to the LSTM (list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of rnn_out_Hsplit is <class 'list'>\n",
      "Length of rnn_out_Hsplit is 28 and the shape of each item is (5, 128)\n"
     ]
    }
   ],
   "source": [
    "rnn_out_Hsplit = sess.run(my_rnn['H_split'], feed_dict=feeds)\n",
    "print('Type of rnn_out_Hsplit is', type(rnn_out_Hsplit))\n",
    "print('Length of rnn_out_Hsplit is %s and the shape of each item is %s' % (len(rnn_out_Hsplit), rnn_out_Hsplit[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output from the LSTM (list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of rnn_out_LSTM_O is <class 'list'>\n",
      "Length of rnn_out_LSTM_O is 28 and the shape of each item is (5, 128)\n"
     ]
    }
   ],
   "source": [
    "rnn_out_LSTM_O = sess.run(my_rnn['LSTM_O'], feed_dict=feeds)\n",
    "print('Type of rnn_out_LSTM_O is', type(rnn_out_LSTM_O))\n",
    "print('Length of rnn_out_LSTM_O is %s and the shape of each item is %s' % (len(rnn_out_LSTM_O), rnn_out_LSTM_O[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State from the LSTM (LSTMStateTuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of rnn_out_LSTM_S is <class 'tensorflow.python.ops.rnn_cell_impl.LSTMStateTuple'>\n",
      "Length of rnn_out_LSTM_S is 2 and the shape of each item is (5, 128)\n"
     ]
    }
   ],
   "source": [
    "rnn_out_LSTM_S = sess.run(my_rnn['LSTM_S'], feed_dict=feeds)\n",
    "print('Type of rnn_out_LSTM_S is', type(rnn_out_LSTM_S))\n",
    "print('Length of rnn_out_LSTM_S is %s and the shape of each item is %s' % (len(rnn_out_LSTM_S), rnn_out_LSTM_S[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of rnn_out_O is <class 'numpy.ndarray'>\n",
      "Shape of rnn_out_O is (5, 10)\n"
     ]
    }
   ],
   "source": [
    "rnn_out_O = sess.run(my_rnn['O'], feed_dict=feeds)\n",
    "print('Type of rnn_out_O is', type(rnn_out_O))\n",
    "print('Shape of rnn_out_O is', rnn_out_O.shape)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
