{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "#Clear TF memory\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from .npz file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainlabel', 'trainimg', 'testimg', 'testlabel']\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "loadpath = cwd + \"/data/trainset.npz\"\n",
    "l = np.load(loadpath)\n",
    "l\n",
    "print (l.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trainlabel', 'trainimg', 'testimg', 'testlabel']\n",
      "69 train images loaded\n",
      "18 test images loaded\n",
      "900 dimensional input\n",
      "2 classes\n"
     ]
    }
   ],
   "source": [
    "# Load them!\n",
    "cwd = os.getcwd()\n",
    "loadpath = cwd + \"/data/trainset.npz\"\n",
    "l = np.load(loadpath)\n",
    "\n",
    "# See what's in here\n",
    "print (l.files)\n",
    "\n",
    "# Parse data\n",
    "trainimg = l['trainimg']\n",
    "trainlabel = l['trainlabel']\n",
    "testimg = l['testimg']\n",
    "testlabel = l['testlabel']\n",
    "# use_gray = l['use_gray']\n",
    "ntrain = trainimg.shape[0]\n",
    "nclass = trainlabel.shape[1]\n",
    "dim    = trainimg.shape[1]\n",
    "ntest  = testimg.shape[0]\n",
    "print (\"%d train images loaded\" % (ntrain))\n",
    "print (\"%d test images loaded\" % (ntest))\n",
    "print (\"%d dimensional input\" % (dim))\n",
    "print (\"%d classes\" % (nclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 900)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainlabel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(0)\n",
    "\n",
    "#Parameter of logistic regression\n",
    "learning_rate = 0.001\n",
    "train_epochs = 1000\n",
    "batch_size = 10\n",
    "display_step = 100\n",
    "\n",
    "#Create TF graph of logistic regression\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, dim])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, nclass])\n",
    "\n",
    "#Weights & biases\n",
    "W = tf.Variable(tf.zeros([dim, nclass]), name='weights')\n",
    "b = tf.Variable(tf.zeros([nclass]), name='biases')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WEIGHT_DECAY_FACTOR = 1 #0.000001\n",
    "l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])\n",
    "\n",
    "y_pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred), reduction_indices=1))\n",
    "loss = loss + WEIGHT_DECAY_FACTOR*l2_loss\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000, loss= 0.6800\n",
      "     Train Accuracy: 0.5000\n",
      "     Test Accuracy: 0.2778\n",
      "Epoch: 100/1000, loss= 0.6238\n",
      "     Train Accuracy: 0.9000\n",
      "     Test Accuracy: 0.7222\n",
      "Epoch: 200/1000, loss= 0.5297\n",
      "     Train Accuracy: 0.9000\n",
      "     Test Accuracy: 0.7222\n",
      "Epoch: 300/1000, loss= 0.5253\n",
      "     Train Accuracy: 1.0000\n",
      "     Test Accuracy: 0.7778\n",
      "Epoch: 400/1000, loss= 0.5806\n",
      "     Train Accuracy: 0.8000\n",
      "     Test Accuracy: 0.7778\n",
      "Epoch: 500/1000, loss= 0.5085\n",
      "     Train Accuracy: 0.9000\n",
      "     Test Accuracy: 0.7778\n",
      "Epoch: 600/1000, loss= 0.5377\n",
      "     Train Accuracy: 0.9000\n",
      "     Test Accuracy: 0.6667\n",
      "Epoch: 700/1000, loss= 0.5686\n",
      "     Train Accuracy: 0.9000\n",
      "     Test Accuracy: 0.7222\n",
      "Epoch: 800/1000, loss= 0.5344\n",
      "     Train Accuracy: 0.9000\n",
      "     Test Accuracy: 0.7778\n",
      "Epoch: 900/1000, loss= 0.5302\n",
      "     Train Accuracy: 1.0000\n",
      "     Test Accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(train_epochs):\n",
    "    avg_loss = 0\n",
    "    num_batch = int(ntrain/batch_size)\n",
    "    #Loop over all batches\n",
    "    for i in range(num_batch):\n",
    "        random_idx = np.random.randint(ntrain, size=batch_size)\n",
    "        batch_x = trainimg[random_idx, :]\n",
    "        batch_y = trainlabel[random_idx, :]\n",
    "        \n",
    "        #Fit training using batch data\n",
    "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "        #Compute avg_loss\n",
    "        avg_loss += sess.run(loss, feed_dict={x: batch_x, y: batch_y}) / num_batch\n",
    "        \n",
    "    #Display logs per epoch step\n",
    "    if epoch % display_step == 0:\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        test_accuracy = sess.run(accuracy, feed_dict={x: testimg, y: testlabel})\n",
    "        \n",
    "        print('Epoch: %d/%d, loss= %.4f\\n     Train Accuracy: %.4f\\n     Test Accuracy: %.4f' % (epoch, train_epochs, avg_loss, train_accuracy, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
